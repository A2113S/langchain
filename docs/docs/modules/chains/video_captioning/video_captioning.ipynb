{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Captioning\n",
    "This notebook shows how to use VideoCaptioningChain, which is implemented using Langchain's ImageCaptionLoader and AssemblyAI to produce .srt files.\n",
    "\n",
    "This system autogenerates both subtitles and closed captions from a video URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required parameters:**\n",
    "\n",
    "* llm: The language model this chain will use to get suggestions on how to refine the closed-captions\n",
    "* assemblyai_key: The API key for AssemblyAI, used to generate the subtitles\n",
    "\n",
    "**Optional Parameters:**\n",
    "\n",
    "* verbose (Default: True): Sets verbose mode for downstream chain calls\n",
    "* use_logging (Default: True): Log the chain's processes in run manager\n",
    "* frame_skip (Default: 3): Choose how many video frames to skip during processing. Increasing it results in faster execution, but less accurate results\n",
    "* image_delta_threshold (Default: 3000000): Set the sensitivity for what the image processor considers a change in scenery in the video, used to delimit closed captions. Higher = less sensitive\n",
    "* closed_caption_char_limit (Default: 20): Sets the character limit on closed captions\n",
    "* closed_caption_similarity_threshold (Default: 90): Sets the percentage value to how similar two closed caption models should be in order to be clustered into one longer closed caption\n",
    "* use_unclustered_video_models (Default: False): If true, closed captions that could not be clustered will be included. May result in spontaneous behaviour from closed captions such as very short lasting captions or fast-changing captions. Enabling this is experimental and not recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new VideoCaptioningChain chain...\u001b[0m\n",
      "Loading processors...\n",
      "Finished loading processors.\n",
      "Generating subtitles from audio...\n",
      "Finished generating subtitles:\n",
      "start_time: 250, end_time: 4106, subtitle_text: Any chives? What were you eating?\n",
      "start_time: 4218, end_time: 7274, subtitle_text: Chives. We are not going off on some wild goose chase.\n",
      "start_time: 7322, end_time: 10378, subtitle_text: Who's in? How easy? A little tighter.\n",
      "start_time: 10394, end_time: 12830, subtitle_text: In at the couch. Yeah, it's a little tight in the couch.\n",
      "start_time: 13970, end_time: 14620, subtitle_text: Did you eat?\n",
      "Generating closed captions from video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomsa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating closed captions:\n",
      "start_time: 0, end_time: 1066.6666666666667, image_description: an image of a man with a mustache and mustache\n",
      "start_time: 1066.6666666666667, end_time: 1400.0, image_description: an image of a man with a mustache and mustache\n",
      "start_time: 1400.0, end_time: 1733.3333333333335, image_description: an image of a man with a mustache and mustache\n",
      "start_time: 1733.3333333333335, end_time: 2066.6666666666665, image_description: an image of a man with a mustache and a face\n",
      "start_time: 2066.6666666666665, end_time: 2400.0, image_description: an image of a man with a mustache in an office\n",
      "start_time: 2400.0, end_time: 2733.3333333333335, image_description: an image of two people standing in front of a building\n",
      "start_time: 2733.3333333333335, end_time: 4116.666666666666, image_description: an image of two people standing in front of a house\n",
      "start_time: 4116.666666666666, end_time: 4450.0, image_description: an image of two people standing in front of a house\n",
      "start_time: 4450.0, end_time: 4783.333333333333, image_description: an image of the moon with the words moon\n",
      "start_time: 4783.333333333333, end_time: 5116.666666666666, image_description: an image of the words no 4 a and a\n",
      "start_time: 5116.666666666666, end_time: 5450.0, image_description: an image of the words no 4 a in white on a black background\n",
      "start_time: 5450.0, end_time: 5783.333333333333, image_description: an image of a group of people in a room\n",
      "start_time: 5783.333333333333, end_time: 6466.666666666667, image_description: an image of a group of people in a room\n",
      "start_time: 6466.666666666667, end_time: 6800.0, image_description: an image of a group of people in a room\n",
      "start_time: 6800.0, end_time: 7833.333333333333, image_description: an image of a group of people in a room\n",
      "start_time: 7833.333333333333, end_time: 8166.666666666666, image_description: an image of a group of people in a room\n",
      "start_time: 8166.666666666666, end_time: 8500.0, image_description: an image of a group of people in a room\n",
      "start_time: 8500.0, end_time: 8833.333333333334, image_description: an image of the words every day in green on a black background\n",
      "start_time: 8833.333333333334, end_time: 9516.666666666666, image_description: an image of a cartoon character holding a large object\n",
      "start_time: 9516.666666666666, end_time: 9850.0, image_description: an image of a man carrying a giant bag\n",
      "start_time: 9850.0, end_time: 10183.333333333334, image_description: an image of a man in a suit and tie standing on a street\n",
      "start_time: 10183.333333333334, end_time: 10516.666666666666, image_description: an image of a man in a suit and tie standing on a street\n",
      "start_time: 10516.666666666666, end_time: 10850.0, image_description: an image of a man in a suit shop\n",
      "start_time: 10850.0, end_time: 11183.333333333334, image_description: an image of a man in a suit shop\n",
      "start_time: 11183.333333333334, end_time: 11516.666666666666, image_description: an image of a man in a suit shop\n",
      "start_time: 11516.666666666666, end_time: 12550.0, image_description: an image of the simpsons family's burgers\n",
      "start_time: 12550.0, end_time: 12883.333333333332, image_description: an image of the simpsons family's logo\n",
      "start_time: 12883.333333333332, end_time: 13216.666666666666, image_description: an image of a quote that says the simpsons family do burgers\n",
      "start_time: 13216.666666666666, end_time: 14250.0, image_description: an image of a knight in the woods\n",
      "start_time: 14250.0, end_time: 14583.333333333334, image_description: an image of a robot in the woods\n",
      "start_time: 14583.333333333334, end_time: 14916.666666666666, image_description: an image of a black screen with a white border\n",
      "Refining closed captions...\n",
      "start_time: 0, end_time: 1733.3333333333335, image_description: an image of a man with a mustache and mustache\n",
      "start_time: 1733.3333333333335, end_time: 2066.6666666666665, image_description: an image of a man with a mustache and a face\n",
      "start_time: 2066.6666666666665, end_time: 2400.0, image_description: an image of a man with a mustache in an office\n",
      "start_time: 2400.0, end_time: 2733.3333333333335, image_description: an image of two people standing in front of a building\n",
      "start_time: 2733.3333333333335, end_time: 4450.0, image_description: an image of two people standing in front of a house\n",
      "start_time: 4450.0, end_time: 4783.333333333333, image_description: an image of the moon with the words moon\n",
      "start_time: 4783.333333333333, end_time: 5116.666666666666, image_description: an image of the words no 4 a and a\n",
      "start_time: 5116.666666666666, end_time: 5450.0, image_description: an image of the words no 4 a in white on a black background\n",
      "start_time: 5450.0, end_time: 8500.0, image_description: an image of a group of people in a room\n",
      "start_time: 8500.0, end_time: 8833.333333333334, image_description: an image of the words every day in green on a black background\n",
      "start_time: 8833.333333333334, end_time: 9516.666666666666, image_description: an image of a cartoon character holding a large object\n",
      "start_time: 9516.666666666666, end_time: 9850.0, image_description: an image of a man carrying a giant bag\n",
      "start_time: 9850.0, end_time: 10516.666666666666, image_description: an image of a man in a suit and tie standing on a street\n",
      "start_time: 10516.666666666666, end_time: 11516.666666666666, image_description: an image of a man in a suit shop\n",
      "start_time: 11516.666666666666, end_time: 12550.0, image_description: an image of the simpsons family's burgers\n",
      "start_time: 12550.0, end_time: 12883.333333333332, image_description: an image of the simpsons family's logo\n",
      "start_time: 12883.333333333332, end_time: 13216.666666666666, image_description: an image of a quote that says the simpsons family do burgers\n",
      "start_time: 13216.666666666666, end_time: 14250.0, image_description: an image of a knight in the woods\n",
      "start_time: 14250.0, end_time: 14583.333333333334, image_description: an image of a robot in the woods\n",
      "start_time: 14583.333333333334, end_time: 14916.666666666666, image_description: an image of a black screen with a white border\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "I will provide you with several descriptions depicting events in one scene.\n",
      "Your task is to combine these descriptions into one description that contains only the important details from all descriptions.\n",
      "Especially if the two descriptions are very similar, make sure your response doesn't repeat itself.\n",
      "IMPORTANT: Do not make up a description. Do not make up events or anything that happened outside of the descriptions I am to provide you.\n",
      "I will now provide an example for you to learn from:\n",
      "Example: Description 1: The cat is at the beach, Description 2: The cat is eating lunch, Description 3: The cat is enjoying his time with friends\n",
      "Result: The cat is at the beach, eating lunch with his friends\n",
      "Now that I gave you the example, I will explain to you what exactly you need to return:\n",
      "Just give back one description, the description which is a combination of the descriptions you are provided with.\n",
      "Do not include anything else in your response other than the combined description.\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "Here is the data for you to work with in order to formulate your response:\n",
      "\n",
      "Human: Description 1: an image of a man with a mustache and mustache, Description 2: an image of a man with a mustache and a face, Description 3: an image of a man with a mustache in an office\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Given a closed-caption description of an image or scene, remove any common prefixes like \"an image of,\" \"a scene of,\" or \"footage of.\" \n",
      "For instance, if the description is \"an image of a beautiful landscape,\" the modified version should be \"a beautiful landscape.\"\n",
      "\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "\n",
      "Here are some examples:\n",
      "\n",
      "Input: an image of a beautiful landscape\n",
      "Result: a beautiful landscape\n",
      "\n",
      "Input: a scene of people enjoying a picnic\n",
      "Result: people enjoying a picnic\n",
      "\n",
      "Below is the input for you to generate the result from:\n",
      "\n",
      "Human: Input: An image of a man with a mustache, visible facial features, situated in an office.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "I will provide you with several descriptions depicting events in one scene.\n",
      "Your task is to combine these descriptions into one description that contains only the important details from all descriptions.\n",
      "Especially if the two descriptions are very similar, make sure your response doesn't repeat itself.\n",
      "IMPORTANT: Do not make up a description. Do not make up events or anything that happened outside of the descriptions I am to provide you.\n",
      "I will now provide an example for you to learn from:\n",
      "Example: Description 1: The cat is at the beach, Description 2: The cat is eating lunch, Description 3: The cat is enjoying his time with friends\n",
      "Result: The cat is at the beach, eating lunch with his friends\n",
      "Now that I gave you the example, I will explain to you what exactly you need to return:\n",
      "Just give back one description, the description which is a combination of the descriptions you are provided with.\n",
      "Do not include anything else in your response other than the combined description.\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "Here is the data for you to work with in order to formulate your response:\n",
      "\n",
      "Human: Description 1: an image of two people standing in front of a building, Description 2: an image of two people standing in front of a house\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Given a closed-caption description of an image or scene, remove any common prefixes like \"an image of,\" \"a scene of,\" or \"footage of.\" \n",
      "For instance, if the description is \"an image of a beautiful landscape,\" the modified version should be \"a beautiful landscape.\"\n",
      "\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "\n",
      "Here are some examples:\n",
      "\n",
      "Input: an image of a beautiful landscape\n",
      "Result: a beautiful landscape\n",
      "\n",
      "Input: a scene of people enjoying a picnic\n",
      "Result: people enjoying a picnic\n",
      "\n",
      "Below is the input for you to generate the result from:\n",
      "\n",
      "Human: Input: An image of two people standing in front of a building, which is a house.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "I will provide you with several descriptions depicting events in one scene.\n",
      "Your task is to combine these descriptions into one description that contains only the important details from all descriptions.\n",
      "Especially if the two descriptions are very similar, make sure your response doesn't repeat itself.\n",
      "IMPORTANT: Do not make up a description. Do not make up events or anything that happened outside of the descriptions I am to provide you.\n",
      "I will now provide an example for you to learn from:\n",
      "Example: Description 1: The cat is at the beach, Description 2: The cat is eating lunch, Description 3: The cat is enjoying his time with friends\n",
      "Result: The cat is at the beach, eating lunch with his friends\n",
      "Now that I gave you the example, I will explain to you what exactly you need to return:\n",
      "Just give back one description, the description which is a combination of the descriptions you are provided with.\n",
      "Do not include anything else in your response other than the combined description.\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "Here is the data for you to work with in order to formulate your response:\n",
      "\n",
      "Human: Description 1: an image of the words no 4 a in white on a black background, Description 2: an image of a group of people in a room, Description 3: an image of the words every day in green on a black background\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Given a closed-caption description of an image or scene, remove any common prefixes like \"an image of,\" \"a scene of,\" or \"footage of.\" \n",
      "For instance, if the description is \"an image of a beautiful landscape,\" the modified version should be \"a beautiful landscape.\"\n",
      "\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "\n",
      "Here are some examples:\n",
      "\n",
      "Input: an image of a beautiful landscape\n",
      "Result: a beautiful landscape\n",
      "\n",
      "Input: a scene of people enjoying a picnic\n",
      "Result: people enjoying a picnic\n",
      "\n",
      "Below is the input for you to generate the result from:\n",
      "\n",
      "Human: Input: The image depicts the words 'no 4 a' in white and 'every day' in green on a black background, along with a group of people in a room.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "I will provide you with several descriptions depicting events in one scene.\n",
      "Your task is to combine these descriptions into one description that contains only the important details from all descriptions.\n",
      "Especially if the two descriptions are very similar, make sure your response doesn't repeat itself.\n",
      "IMPORTANT: Do not make up a description. Do not make up events or anything that happened outside of the descriptions I am to provide you.\n",
      "I will now provide an example for you to learn from:\n",
      "Example: Description 1: The cat is at the beach, Description 2: The cat is eating lunch, Description 3: The cat is enjoying his time with friends\n",
      "Result: The cat is at the beach, eating lunch with his friends\n",
      "Now that I gave you the example, I will explain to you what exactly you need to return:\n",
      "Just give back one description, the description which is a combination of the descriptions you are provided with.\n",
      "Do not include anything else in your response other than the combined description.\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "Here is the data for you to work with in order to formulate your response:\n",
      "\n",
      "Human: Description 1: an image of the simpsons family's burgers, Description 2: an image of the simpsons family's logo\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Given a closed-caption description of an image or scene, remove any common prefixes like \"an image of,\" \"a scene of,\" or \"footage of.\" \n",
      "For instance, if the description is \"an image of a beautiful landscape,\" the modified version should be \"a beautiful landscape.\"\n",
      "\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "\n",
      "Here are some examples:\n",
      "\n",
      "Input: an image of a beautiful landscape\n",
      "Result: a beautiful landscape\n",
      "\n",
      "Input: a scene of people enjoying a picnic\n",
      "Result: people enjoying a picnic\n",
      "\n",
      "Below is the input for you to generate the result from:\n",
      "\n",
      "Human: Input: An image of the Simpsons family's burgers with their logo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "I will provide you with several descriptions depicting events in one scene.\n",
      "Your task is to combine these descriptions into one description that contains only the important details from all descriptions.\n",
      "Especially if the two descriptions are very similar, make sure your response doesn't repeat itself.\n",
      "IMPORTANT: Do not make up a description. Do not make up events or anything that happened outside of the descriptions I am to provide you.\n",
      "I will now provide an example for you to learn from:\n",
      "Example: Description 1: The cat is at the beach, Description 2: The cat is eating lunch, Description 3: The cat is enjoying his time with friends\n",
      "Result: The cat is at the beach, eating lunch with his friends\n",
      "Now that I gave you the example, I will explain to you what exactly you need to return:\n",
      "Just give back one description, the description which is a combination of the descriptions you are provided with.\n",
      "Do not include anything else in your response other than the combined description.\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "Here is the data for you to work with in order to formulate your response:\n",
      "\n",
      "Human: Description 1: an image of a knight in the woods, Description 2: an image of a robot in the woods\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Given a closed-caption description of an image or scene, remove any common prefixes like \"an image of,\" \"a scene of,\" or \"footage of.\" \n",
      "For instance, if the description is \"an image of a beautiful landscape,\" the modified version should be \"a beautiful landscape.\"\n",
      "\n",
      "IMPORTANT: the output in your response should be 'Result:text', where text is the description you generated.\n",
      "\n",
      "Here are some examples:\n",
      "\n",
      "Input: an image of a beautiful landscape\n",
      "Result: a beautiful landscape\n",
      "\n",
      "Input: a scene of people enjoying a picnic\n",
      "Result: people enjoying a picnic\n",
      "\n",
      "Below is the input for you to generate the result from:\n",
      "\n",
      "Human: Input: An image of a knight and a robot in the woods.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Finished refining closed captions:\n",
      "start_time: 0, end_time: 2400.0, image_description: a man with a mustache, visible facial features, situated in an office.\n",
      "start_time: 2400.0, end_time: 4450.0, image_description: two people standing in front of a building, which is a house.\n",
      "start_time: 5116.666666666666, end_time: 8833.333333333334, image_description: The words 'no 4 a' in white and 'every day' in green on a black background, along with a group of people in a room.\n",
      "start_time: 11516.666666666666, end_time: 12883.333333333332, image_description: the Simpsons family's burgers with their logo.\n",
      "start_time: 13216.666666666666, end_time: 14583.333333333334, image_description: a knight and a robot in the woods.\n",
      "Combining subtitles with closed captions...\n",
      "0, 2400.0\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are tasked with enhancing closed-caption descriptions based on corresponding subtitles from the audio of a real movie clip. \n",
      "Assignment details, from highest to lowest priority:\n",
      "\n",
      "1) If the subtitle exceeds {limit} characters, creatively rewrite the description to not exceed the character limit, preserving as many details as you can.\n",
      "    If you feel that you cannot complete the response under the character limit, you must omit details in order to remain below the character limit.\n",
      "    \n",
      "2) If the details in the subtitle provide meaningful additional information to its closed-caption description, incorporate those details into the description.\n",
      "\n",
      "Enhance the closed-caption description by integrating details from the subtitle if they contribute meaningful information.\n",
      "\n",
      "Example:\n",
      "Subtitle: car screeching, tires squealing\n",
      "Closed-Caption Description: A car speeds down the street.\n",
      "\n",
      "Output: Result: A car speeds down the street, its tires screeching and squealing.\n",
      "\n",
      "**IMPORTANT**: Remember your assignment details when formulating your response! YOU MUST NOT EXCEED {limit} CHARACTERS.\n",
      "\n",
      "***IMPORTANT***: You must only return the following text in your response. You may not return a response that does not follow the exact format in the next line:\n",
      "Result: Text\n",
      "\n",
      "**** YOU MUST PROVIDE ME WITH THE BEST ANSWER YOU CAN COME UP WITH,\n",
      "**** EVEN IF YOU DEEM THAT IT IS A BAD ONE. YOU MUST ONLY RESPOND IN THE FORMAT IN THE NEXT LINE:\n",
      "Result: Text\n",
      "\n",
      "Below is the data provided, generate a response using this data:\n",
      "\n",
      "Human: Subtitle: Any chives? What were you eating?\n",
      "Closed-Caption Description: a man with a mustache, visible facial features, situated in an office.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "2400.0, 4450.0\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are tasked with enhancing closed-caption descriptions based on corresponding subtitles from the audio of a real movie clip. \n",
      "Assignment details, from highest to lowest priority:\n",
      "\n",
      "1) If the subtitle exceeds {limit} characters, creatively rewrite the description to not exceed the character limit, preserving as many details as you can.\n",
      "    If you feel that you cannot complete the response under the character limit, you must omit details in order to remain below the character limit.\n",
      "    \n",
      "2) If the details in the subtitle provide meaningful additional information to its closed-caption description, incorporate those details into the description.\n",
      "\n",
      "Enhance the closed-caption description by integrating details from the subtitle if they contribute meaningful information.\n",
      "\n",
      "Example:\n",
      "Subtitle: car screeching, tires squealing\n",
      "Closed-Caption Description: A car speeds down the street.\n",
      "\n",
      "Output: Result: A car speeds down the street, its tires screeching and squealing.\n",
      "\n",
      "**IMPORTANT**: Remember your assignment details when formulating your response! YOU MUST NOT EXCEED {limit} CHARACTERS.\n",
      "\n",
      "***IMPORTANT***: You must only return the following text in your response. You may not return a response that does not follow the exact format in the next line:\n",
      "Result: Text\n",
      "\n",
      "**** YOU MUST PROVIDE ME WITH THE BEST ANSWER YOU CAN COME UP WITH,\n",
      "**** EVEN IF YOU DEEM THAT IT IS A BAD ONE. YOU MUST ONLY RESPOND IN THE FORMAT IN THE NEXT LINE:\n",
      "Result: Text\n",
      "\n",
      "Below is the data provided, generate a response using this data:\n",
      "\n",
      "Human: Subtitle: Any chives? What were you eating?\n",
      "Closed-Caption Description: two people standing in front of a building, which is a house.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are tasked with enhancing closed-caption descriptions based on corresponding subtitles from the audio of a real movie clip. \n",
      "Assignment details, from highest to lowest priority:\n",
      "\n",
      "1) If the subtitle exceeds {limit} characters, creatively rewrite the description to not exceed the character limit, preserving as many details as you can.\n",
      "    If you feel that you cannot complete the response under the character limit, you must omit details in order to remain below the character limit.\n",
      "    \n",
      "2) If the details in the subtitle provide meaningful additional information to its closed-caption description, incorporate those details into the description.\n",
      "\n",
      "Enhance the closed-caption description by integrating details from the subtitle if they contribute meaningful information.\n",
      "\n",
      "Example:\n",
      "Subtitle: car screeching, tires squealing\n",
      "Closed-Caption Description: A car speeds down the street.\n",
      "\n",
      "Output: Result: A car speeds down the street, its tires screeching and squealing.\n",
      "\n",
      "**IMPORTANT**: Remember your assignment details when formulating your response! YOU MUST NOT EXCEED {limit} CHARACTERS.\n",
      "\n",
      "***IMPORTANT***: You must only return the following text in your response. You may not return a response that does not follow the exact format in the next line:\n",
      "Result: Text\n",
      "\n",
      "**** YOU MUST PROVIDE ME WITH THE BEST ANSWER YOU CAN COME UP WITH,\n",
      "**** EVEN IF YOU DEEM THAT IT IS A BAD ONE. YOU MUST ONLY RESPOND IN THE FORMAT IN THE NEXT LINE:\n",
      "Result: Text\n",
      "\n",
      "Below is the data provided, generate a response using this data:\n",
      "\n",
      "Human: Subtitle: Chives. We are not going off on some wild goose chase.\n",
      "Closed-Caption Description: two people standing in front of a building, which is a house.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "5116.666666666666, 8833.333333333334\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are tasked with enhancing closed-caption descriptions based on corresponding subtitles from the audio of a real movie clip. \n",
      "Assignment details, from highest to lowest priority:\n",
      "\n",
      "1) If the subtitle exceeds {limit} characters, creatively rewrite the description to not exceed the character limit, preserving as many details as you can.\n",
      "    If you feel that you cannot complete the response under the character limit, you must omit details in order to remain below the character limit.\n",
      "    \n",
      "2) If the details in the subtitle provide meaningful additional information to its closed-caption description, incorporate those details into the description.\n",
      "\n",
      "Enhance the closed-caption description by integrating details from the subtitle if they contribute meaningful information.\n",
      "\n",
      "Example:\n",
      "Subtitle: car screeching, tires squealing\n",
      "Closed-Caption Description: A car speeds down the street.\n",
      "\n",
      "Output: Result: A car speeds down the street, its tires screeching and squealing.\n",
      "\n",
      "**IMPORTANT**: Remember your assignment details when formulating your response! YOU MUST NOT EXCEED {limit} CHARACTERS.\n",
      "\n",
      "***IMPORTANT***: You must only return the following text in your response. You may not return a response that does not follow the exact format in the next line:\n",
      "Result: Text\n",
      "\n",
      "**** YOU MUST PROVIDE ME WITH THE BEST ANSWER YOU CAN COME UP WITH,\n",
      "**** EVEN IF YOU DEEM THAT IT IS A BAD ONE. YOU MUST ONLY RESPOND IN THE FORMAT IN THE NEXT LINE:\n",
      "Result: Text\n",
      "\n",
      "Below is the data provided, generate a response using this data:\n",
      "\n",
      "Human: Subtitle: Chives. We are not going off on some wild goose chase.\n",
      "Closed-Caption Description: The words 'no 4 a' in white and 'every day' in green on a black background, along with a group of people in a room.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are tasked with enhancing closed-caption descriptions based on corresponding subtitles from the audio of a real movie clip. \n",
      "Assignment details, from highest to lowest priority:\n",
      "\n",
      "1) If the subtitle exceeds {limit} characters, creatively rewrite the description to not exceed the character limit, preserving as many details as you can.\n",
      "    If you feel that you cannot complete the response under the character limit, you must omit details in order to remain below the character limit.\n",
      "    \n",
      "2) If the details in the subtitle provide meaningful additional information to its closed-caption description, incorporate those details into the description.\n",
      "\n",
      "Enhance the closed-caption description by integrating details from the subtitle if they contribute meaningful information.\n",
      "\n",
      "Example:\n",
      "Subtitle: car screeching, tires squealing\n",
      "Closed-Caption Description: A car speeds down the street.\n",
      "\n",
      "Output: Result: A car speeds down the street, its tires screeching and squealing.\n",
      "\n",
      "**IMPORTANT**: Remember your assignment details when formulating your response! YOU MUST NOT EXCEED {limit} CHARACTERS.\n",
      "\n",
      "***IMPORTANT***: You must only return the following text in your response. You may not return a response that does not follow the exact format in the next line:\n",
      "Result: Text\n",
      "\n",
      "**** YOU MUST PROVIDE ME WITH THE BEST ANSWER YOU CAN COME UP WITH,\n",
      "**** EVEN IF YOU DEEM THAT IT IS A BAD ONE. YOU MUST ONLY RESPOND IN THE FORMAT IN THE NEXT LINE:\n",
      "Result: Text\n",
      "\n",
      "Below is the data provided, generate a response using this data:\n",
      "\n",
      "Human: Subtitle: Who's in? How easy? A little tighter.\n",
      "Closed-Caption Description: The words 'no 4 a' in white and 'every day' in green on a black background, along with a group of people in a room.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "11516.666666666666, 12883.333333333332\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are tasked with enhancing closed-caption descriptions based on corresponding subtitles from the audio of a real movie clip. \n",
      "Assignment details, from highest to lowest priority:\n",
      "\n",
      "1) If the subtitle exceeds {limit} characters, creatively rewrite the description to not exceed the character limit, preserving as many details as you can.\n",
      "    If you feel that you cannot complete the response under the character limit, you must omit details in order to remain below the character limit.\n",
      "    \n",
      "2) If the details in the subtitle provide meaningful additional information to its closed-caption description, incorporate those details into the description.\n",
      "\n",
      "Enhance the closed-caption description by integrating details from the subtitle if they contribute meaningful information.\n",
      "\n",
      "Example:\n",
      "Subtitle: car screeching, tires squealing\n",
      "Closed-Caption Description: A car speeds down the street.\n",
      "\n",
      "Output: Result: A car speeds down the street, its tires screeching and squealing.\n",
      "\n",
      "**IMPORTANT**: Remember your assignment details when formulating your response! YOU MUST NOT EXCEED {limit} CHARACTERS.\n",
      "\n",
      "***IMPORTANT***: You must only return the following text in your response. You may not return a response that does not follow the exact format in the next line:\n",
      "Result: Text\n",
      "\n",
      "**** YOU MUST PROVIDE ME WITH THE BEST ANSWER YOU CAN COME UP WITH,\n",
      "**** EVEN IF YOU DEEM THAT IT IS A BAD ONE. YOU MUST ONLY RESPOND IN THE FORMAT IN THE NEXT LINE:\n",
      "Result: Text\n",
      "\n",
      "Below is the data provided, generate a response using this data:\n",
      "\n",
      "Human: Subtitle: In at the couch. Yeah, it's a little tight in the couch.\n",
      "Closed-Caption Description: the Simpsons family's burgers with their logo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "13216.666666666666, 14583.333333333334\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are tasked with enhancing closed-caption descriptions based on corresponding subtitles from the audio of a real movie clip. \n",
      "Assignment details, from highest to lowest priority:\n",
      "\n",
      "1) If the subtitle exceeds {limit} characters, creatively rewrite the description to not exceed the character limit, preserving as many details as you can.\n",
      "    If you feel that you cannot complete the response under the character limit, you must omit details in order to remain below the character limit.\n",
      "    \n",
      "2) If the details in the subtitle provide meaningful additional information to its closed-caption description, incorporate those details into the description.\n",
      "\n",
      "Enhance the closed-caption description by integrating details from the subtitle if they contribute meaningful information.\n",
      "\n",
      "Example:\n",
      "Subtitle: car screeching, tires squealing\n",
      "Closed-Caption Description: A car speeds down the street.\n",
      "\n",
      "Output: Result: A car speeds down the street, its tires screeching and squealing.\n",
      "\n",
      "**IMPORTANT**: Remember your assignment details when formulating your response! YOU MUST NOT EXCEED {limit} CHARACTERS.\n",
      "\n",
      "***IMPORTANT***: You must only return the following text in your response. You may not return a response that does not follow the exact format in the next line:\n",
      "Result: Text\n",
      "\n",
      "**** YOU MUST PROVIDE ME WITH THE BEST ANSWER YOU CAN COME UP WITH,\n",
      "**** EVEN IF YOU DEEM THAT IT IS A BAD ONE. YOU MUST ONLY RESPOND IN THE FORMAT IN THE NEXT LINE:\n",
      "Result: Text\n",
      "\n",
      "Below is the data provided, generate a response using this data:\n",
      "\n",
      "Human: Subtitle: Did you eat?\n",
      "Closed-Caption Description: a knight and a robot in the woods.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Finished combining subtitles with closed captions:\n",
      "start_time: 250, end_time: 2400.0, closed_caption: [A man with a mustache, visibly distinct facial features, situated in an office, inquires about chives and what was being eaten.] Any chives? What were you eating?\n",
      "start_time: 2400.0, end_time: 4106, closed_caption: [Two people stand before a house, one asking the other about their meal, \"Any chives? What were you eating?\"] Any chives? What were you eating?\n",
      "start_time: 4218, end_time: 4450.0, closed_caption: [Two people stand before a house, dismissing the idea of a wild goose chase.] Chives. We are not going off on some wild goose chase.\n",
      "start_time: 5116.666666666666, end_time: 7274, closed_caption: [The words 'no 4 a' in white and 'every day' in green appear on a black background. A group of people gather in a room. Someone mentions chives and dismisses a wild goose chase.] Chives. We are not going off on some wild goose chase.\n",
      "start_time: 7322, end_time: 8833.333333333334, closed_caption: [A group of people in a room ask, \"Who's in? How easy? A little tighter.\" The words 'no 4 a' in white and 'every day' in green appear on a black background.] Who's in? How easy? A little tighter.\n",
      "start_time: 11516.666666666666, end_time: 12830, closed_caption: [The Simpsons family's burgers, bearing their logo, are nestled a bit snugly in the couch.] In at the couch. Yeah, it's a little tight in the couch.\n",
      "start_time: 12830, end_time: 12883.333333333332, closed_caption: [the Simpsons family's burgers with their logo.]\n",
      "start_time: 13970, end_time: 14583.333333333334, closed_caption: [In the woods, a knight asks a robot, \"Did you eat?\"] Did you eat?\n",
      "Generating SRT file...\n",
      "Finished generating srt file.\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "1\n",
      "00:00:00,250 --> 00:00:02,400\n",
      "[A man with a mustache, visibly distinct facial features, situated in an office, inquires about chives and what was being eaten.] Any chives? What were you eating?\n",
      "\n",
      "2\n",
      "00:00:02,400 --> 00:00:04,106\n",
      "[Two people stand before a house, one asking the other about their meal, \"Any chives? What were you eating?\"] Any chives? What were you eating?\n",
      "\n",
      "3\n",
      "00:00:04,218 --> 00:00:04,450\n",
      "[Two people stand before a house, dismissing the idea of a wild goose chase.] Chives. We are not going off on some wild goose chase.\n",
      "\n",
      "4\n",
      "00:00:05,116 --> 00:00:07,274\n",
      "[The words 'no 4 a' in white and 'every day' in green appear on a black background. A group of people gather in a room. Someone mentions chives and dismisses a wild goose chase.] Chives. We are not going off on some wild goose chase.\n",
      "\n",
      "5\n",
      "00:00:07,322 --> 00:00:08,833\n",
      "[A group of people in a room ask, \"Who's in? How easy? A little tighter.\" The words 'no 4 a' in white and 'every day' in green appear on a black background.] Who's in? How easy? A little tighter.\n",
      "\n",
      "6\n",
      "00:00:11,516 --> 00:00:12,830\n",
      "[The Simpsons family's burgers, bearing their logo, are nestled a bit snugly in the couch.] In at the couch. Yeah, it's a little tight in the couch.\n",
      "\n",
      "7\n",
      "00:00:12,830 --> 00:00:12,883\n",
      "[the Simpsons family's burgers with their logo.]\n",
      "\n",
      "8\n",
      "00:00:13,970 --> 00:00:14,583\n",
      "[In the woods, a knight asks a robot, \"Did you eat?\"] Did you eat?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.video_captioning import VideoCaptioningChain\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "\n",
    "\n",
    "#TODO: env variable for keys\n",
    "\n",
    "# The runtime for this instance is currently is about 3 minutes, but may vary based on your computer specs.\n",
    "chain = VideoCaptioningChain(\n",
    "    llm=ChatOpenAI(model=\"gpt-4\", max_tokens=4000, openai_api_key=\"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\"),\n",
    "    assemblyai_key=\"f50c08e20ecd4544b175953636f0b936\",\n",
    "    frame_skip=20,\n",
    "    image_delta_threshold=3000000,\n",
    "    closed_caption_similarity_threshold=90,\n",
    ")\n",
    "\n",
    "# https://ia804703.us.archive.org/27/items/uh-oh-here-we-go-again/Uh-Oh%2C%20Here%20we%20go%20again.mp4\n",
    "# https://ia601200.us.archive.org/9/items/f58703d4-61e6-4f8f-8c08-b42c7e16f7cb/f58703d4-61e6-4f8f-8c08-b42c7e16f7cb.mp4\n",
    "result = chain.run(video_file_path=\"https://ia904700.us.archive.org/22/items/any-chibes/X2Download.com-FXX%20USA%20%C2%ABPromo%20Noon%20-%204A%20Every%20Day%EF%BF%BD%EF%BF%BD%C2%BB%20November%202021%EF%BF%BD%EF%BF%BD-%281080p60%29.mp4\")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
